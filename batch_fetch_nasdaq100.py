#!/usr/bin/env python3
"""
æ‰¹é‡è·å– NASDAQ 100 è‚¡ç¥¨å†å²æ•°æ® - ç®€åŒ–æ¶æ„

æ”¯æŒä¸‰ç§æ¨¡å¼:
1. æµ‹è¯•æ¨¡å¼: python batch_fetch_nasdaq100.py --test     (é»˜è®¤ï¼Œå¤„ç†6åªä»£è¡¨æ€§è‚¡ç¥¨)
2. å®Œæ•´æ¨¡å¼: python batch_fetch_nasdaq100.py --full     (å¤„ç†å…¨éƒ¨NASDAQ 100è‚¡ç¥¨)
3. åˆ—è¡¨æ¨¡å¼: python batch_fetch_nasdaq100.py --failed-list AAPL MSFT GOOGL  (å¤„ç†æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨)

å…¶ä»–å‚æ•°:
--start-date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤2008-01-01
--max-count: æœ€å¤§å¤„ç†æ•°é‡ (ä»…æ ‡å‡†æ¨¡å¼)
--start-from: å¼€å§‹ä½ç½® (ä»…æ ‡å‡†æ¨¡å¼)
"""

import pandas as pd
import os
import time
import argparse
from datetime import datetime
from src.ibkr_fetcher import get_stock_data
from src.logger_config import get_logger


# è·å–è½»é‡çº§logger
logger = get_logger("nasdaq_batch")

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='æ‰¹é‡è·å– NASDAQ 100 è‚¡ç¥¨å†å²æ•°æ®')
    
    # ä¸»è¦æ¨¡å¼é€‰æ‹©
    group = parser.add_mutually_exclusive_group()
    group.add_argument('--test', action='store_true', 
                      help='æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰6åªè‚¡ç¥¨')
    group.add_argument('--full', action='store_true', 
                      help='å®Œæ•´æ¨¡å¼ï¼šå¤„ç†å…¨éƒ¨è‚¡ç¥¨')
    group.add_argument('--failed-list', type=str, nargs='+',
                      help='å¤±è´¥è‚¡ç¥¨åˆ—è¡¨æ¨¡å¼ï¼šå¤„ç†æŒ‡å®šçš„è‚¡ç¥¨ä»£ç ')
    
    # é€šç”¨å‚æ•°
    parser.add_argument('--start-date', default='2008-01-01',
                       help='å¼€å§‹æ—¥æœŸ (é»˜è®¤: 2008-01-01)')
    parser.add_argument('--max-count', type=int,
                       help='æœ€å¤§å¤„ç†è‚¡ç¥¨æ•°é‡ï¼ˆä»…æ ‡å‡†æ¨¡å¼æœ‰æ•ˆï¼‰')
    parser.add_argument('--start-from', type=int, default=0,
                       help='ä»ç¬¬å‡ ä¸ªè‚¡ç¥¨å¼€å§‹å¤„ç†ï¼ˆä»…æ ‡å‡†æ¨¡å¼æœ‰æ•ˆï¼‰')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æ¨¡å¼ï¼Œé»˜è®¤ä¸ºæµ‹è¯•æ¨¡å¼
    if not args.test and not args.full and not args.failed_list:
        args.test = True
        
    return args

def load_nasdaq100_data(file_path="index/nasdaq100.txt"):
    """åŠ è½½ NASDAQ 100 æ•°æ®æ–‡ä»¶"""
    try:
        df = pd.read_csv(file_path, sep='\t', header=None, names=['symbol', 'entry_date', 'exit_date'])
        df['entry_date'] = pd.to_datetime(df['entry_date'])
        df['exit_date'] = pd.to_datetime(df['exit_date'])
        logger.info(f"æˆåŠŸåŠ è½½ {len(df)} ä¸ª NASDAQ 100 è‚¡ç¥¨ä¿¡æ¯")
        return df
    except Exception as e:
        logger.error(f"åŠ è½½ NASDAQ 100 æ•°æ®å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def create_data_directory():
    """åˆ›å»ºdataç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    if not os.path.exists('data'):
        os.makedirs('data')
        logger.info("åˆ›å»º data ç›®å½•")

def fetch_and_save_stock_data(symbol, start_date, client_id_offset, output_dir="data"):
    """è·å–å•ä¸ªè‚¡ç¥¨æ•°æ®å¹¶ä¿å­˜åˆ°CSV"""
    try:
        logger.info(f"å¼€å§‹è·å– {symbol} å†å²æ•°æ®...")
        
        stock_start_time = time.time()
        df = get_stock_data(symbol, start_date, client_id=client_id_offset)
        stock_end_time = time.time()
        elapsed = stock_end_time - stock_start_time
        
        if not df.empty:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            if output_dir != "data":
                os.makedirs(output_dir, exist_ok=True)
            
            # ç»Ÿä¸€ä½¿ç”¨ {symbol}.csv æ ¼å¼
            csv_path = os.path.join(output_dir, f"{symbol}.csv")
            df.to_csv(csv_path)
            
            # è®¡ç®—æ”¶ç›Šç‡
            total_return = 0
            if len(df) > 1:
                first_price = df['close'].iloc[0]
                last_price = df['close'].iloc[-1]
                total_return = (last_price - first_price) / first_price * 100
            
            logger.info(f"âœ… {symbol}: æˆåŠŸä¿å­˜ {len(df)} æ¡æ•°æ®")
            logger.info(f"   ğŸ“… {df.index.min().strftime('%Y-%m-%d')} åˆ° {df.index.max().strftime('%Y-%m-%d')}")
            logger.info(f"   ğŸ“ˆ æ€»æ”¶ç›Š: {total_return:+.1f}%")
            logger.info(f"   â±ï¸  ç”¨æ—¶: {elapsed:.1f}ç§’")
            
            return {
                'success': True,
                'symbol': symbol,
                'records': len(df),
                'start_date': df.index.min(),
                'end_date': df.index.max(),
                'time_taken': elapsed,
                'file_size_kb': os.path.getsize(csv_path) / 1024,
                'total_return': total_return,
                'csv_path': csv_path,
                'df': df  # è¿”å›DataFrameä¾›ä¸ä¿å­˜æ–‡ä»¶æ—¶ä½¿ç”¨
            }
        else:
            logger.warning(f"âŒ {symbol}: æœªè·å–åˆ°æ•°æ®")
            return {'success': False, 'symbol': symbol, 'error': 'æ— æ•°æ®'}
            
    except Exception as e:
        logger.error(f"âŒ {symbol}: è·å–æ•°æ®å¤±è´¥ - {str(e)}")
        return {'success': False, 'symbol': symbol, 'error': str(e)}

def batch_fetch_stocks(nasdaq_df, test_mode=True, max_count=None, start_from=0, start_date="2008-01-01"):
    """æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®"""
    
    create_data_directory()
    
    symbols = nasdaq_df['symbol'].tolist()
    
    # ç¡®å®šå¤„ç†çš„è‚¡ç¥¨åˆ—è¡¨
    if test_mode:
        # æµ‹è¯•æ¨¡å¼ï¼šé€‰æ‹©ä»£è¡¨æ€§è‚¡ç¥¨
        preferred_symbols = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'NVDA', 'META']
        test_symbols = []
        
        for symbol in preferred_symbols:
            if symbol in symbols:
                test_symbols.append(symbol)
            if len(test_symbols) >= 6:
                break
        
        if len(test_symbols) < 6:
            # å¦‚æœä»£è¡¨æ€§è‚¡ç¥¨ä¸å¤Ÿï¼Œè¡¥å……æ–‡ä»¶ä¸­çš„å‰å‡ ä¸ª
            remaining_needed = 6 - len(test_symbols)
            for symbol in symbols:
                if symbol not in test_symbols:
                    test_symbols.append(symbol)
                    remaining_needed -= 1
                    if remaining_needed <= 0:
                        break
        
        symbols = test_symbols
        print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼: å¤„ç† {len(symbols)} åªä»£è¡¨æ€§è‚¡ç¥¨")
    else:
        # å®Œæ•´æ¨¡å¼æˆ–è‡ªå®šä¹‰æ•°é‡
        if max_count:
            symbols = symbols[start_from:start_from + max_count]
        else:
            symbols = symbols[start_from:]
        print(f"ğŸ­ {'å®Œæ•´' if not max_count else 'è‡ªå®šä¹‰'}æ¨¡å¼: å¤„ç† {len(symbols)} åªè‚¡ç¥¨")
    
    print(f"ğŸ¯ è‚¡ç¥¨åˆ—è¡¨: {symbols}")
    print(f"ğŸ“… æ•°æ®èµ·å§‹: {start_date}")
    print(f"ğŸ’¾ ä¿å­˜ç›®å½•: data/")
    
    results = {'success': [], 'failed': [], 'details': []}
    start_time = time.time()
    
    for i, symbol in enumerate(symbols, 1):
        print(f"\nğŸ“Š å¤„ç†è¿›åº¦: {i}/{len(symbols)} - {symbol}")
        
        client_id = 300 + i
        result = fetch_and_save_stock_data(symbol, start_date, client_id, "data")
        
        if result['success']:
            results['success'].append(symbol)
            results['details'].append(result)
        else:
            results['failed'].append(symbol)
        
        # æ·»åŠ å»¶è¿Ÿ
        if i < len(symbols):
            print("â±ï¸  ç­‰å¾… 3 ç§’...")
            time.sleep(3)
    
    end_time = time.time()
    total_elapsed = end_time - start_time
    
    return results, total_elapsed

def fetch_list_stocks(stock_list, start_date="2008-01-01", save_to_csv=True, output_dir="data"):
    """
    è·å–è‚¡ç¥¨åˆ—è¡¨çš„å†å²æ•°æ®
    
    å‚æ•°:
    stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ (å¦‚ ['AAPL', 'MSFT', 'GOOGL'])
    start_date: å¼€å§‹æ—¥æœŸ (é»˜è®¤: 2008-01-01)
    save_to_csv: æ˜¯å¦ä¿å­˜ä¸ºCSVæ–‡ä»¶ (é»˜è®¤: True)
    output_dir: è¾“å‡ºç›®å½• (é»˜è®¤: data)
    
    è¿”å›:
    dict: åŒ…å«æˆåŠŸå’Œå¤±è´¥ä¿¡æ¯çš„ç»“æœå­—å…¸
    """
    
    logger.info(f"ğŸš€ å¼€å§‹è·å–è‚¡ç¥¨åˆ—è¡¨æ•°æ®: {len(stock_list)} åªè‚¡ç¥¨")
    
    # æ¸…ç†è‚¡ç¥¨ä»£ç åˆ—è¡¨
    cleaned_symbols = []
    skipped_count = 0
    
    for symbol in stock_list:
        if not symbol or symbol.strip() == "":
            continue
        # è·³è¿‡é€€å¸‚è‚¡ç¥¨æ ‡è®°ï¼ˆ$åŒ…å›´ï¼‰
        if symbol.startswith('$') and symbol.endswith('$'):
            logger.warning(f"â­ï¸ è·³è¿‡å·²é€€å¸‚è‚¡ç¥¨: {symbol}")
            skipped_count += 1
            continue
        # æ¸…ç†å¹¶å»é‡
        clean_symbol = symbol.strip().upper()
        if clean_symbol and clean_symbol not in cleaned_symbols:
            cleaned_symbols.append(clean_symbol)
    
    logger.info(f"ğŸ§¹ æ¸…ç†åè‚¡ç¥¨åˆ—è¡¨: {len(cleaned_symbols)} åªï¼ˆè·³è¿‡ {skipped_count} åªé€€å¸‚è‚¡ç¥¨ï¼‰")
    
    if not cleaned_symbols:
        logger.error("æ²¡æœ‰æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç å¯ä»¥å¤„ç†")
        return {'success': {}, 'failed': [], 'details': []}
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if save_to_csv:
        create_data_directory()
        if output_dir != "data":
            os.makedirs(output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–ç»“æœ
    results = {
        'success': {},
        'failed': [],
        'details': []
    }
    
    start_time = time.time()
    
    # å¤„ç†æ¯ä¸ªè‚¡ç¥¨
    for i, symbol in enumerate(cleaned_symbols, 1):
        logger.info(f"ğŸ“Š è¿›åº¦ {i}/{len(cleaned_symbols)}: æ­£åœ¨å¤„ç† {symbol}")
        
        # ä½¿ç”¨ä¸åŒçš„client_idé¿å…å†²çª
        client_id = 200 + i
        
        if save_to_csv:
            # ä¿å­˜åˆ°æ–‡ä»¶æ¨¡å¼
            result = fetch_and_save_stock_data(symbol, start_date, client_id, output_dir)
        else:
            # ä»…è·å–æ•°æ®æ¨¡å¼ï¼Œä¿å­˜åˆ°ä¸´æ—¶ä½ç½®ä½†ä¸ä½œä¸ºæœ€ç»ˆè¾“å‡º
            temp_dir = "/tmp/stock_temp"
            os.makedirs(temp_dir, exist_ok=True)
            result = fetch_and_save_stock_data(symbol, start_date, client_id, temp_dir)
        
        if result['success']:
            # æ ¹æ®æ¨¡å¼å¤„ç†ç»“æœ
            if save_to_csv:
                results['success'][symbol] = result['df']  # ä¿å­˜DataFrame
                results['details'].append({
                    'symbol': symbol,
                    'success': True,
                    'records': result['records'],
                    'start_date': result['start_date'].strftime('%Y-%m-%d'),
                    'end_date': result['end_date'].strftime('%Y-%m-%d'),
                    'file_size_kb': result['file_size_kb'],
                    'total_return': result['total_return'],
                    'csv_path': result['csv_path']
                })
            else:
                results['success'][symbol] = result['df']  # åªä¿å­˜DataFrame
                logger.info(f"âœ… {symbol}: æˆåŠŸè·å– {result['records']} æ¡æ•°æ®ï¼ˆæœªä¿å­˜æ–‡ä»¶ï¼‰")
        else:
            results['failed'].append(symbol)
        
        # è‚¡ç¥¨é—´å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        if i < len(cleaned_symbols):
            time.sleep(3)
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    elapsed_time = time.time() - start_time
    success_count = len(results['success'])
    failed_count = len(results['failed'])
    
    # æ‰“å°æ‘˜è¦
    print(f"\n{'='*60}")
    print(f"ğŸ“Š è‚¡ç¥¨åˆ—è¡¨è·å–å®Œæˆ")
    print(f"{'='*60}")
    print(f"âœ… æˆåŠŸ: {success_count} åª")
    print(f"âŒ å¤±è´¥: {failed_count} åª")
    print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time/60:.1f} åˆ†é’Ÿ")
    
    if results['success']:
        total_records = sum(len(df) for df in results['success'].values())
        print(f"ğŸ”¢ æ€»æ•°æ®æ¡æ•°: {total_records:,}")
        print(f"ğŸ“ æˆåŠŸè‚¡ç¥¨: {list(results['success'].keys())}")
        
        if save_to_csv and results['details']:
            total_size = sum(detail.get('file_size_kb', 0) for detail in results['details'])
            print(f"ğŸ’¾ æ€»æ–‡ä»¶å¤§å°: {total_size:.1f} KB")
    
    if results['failed']:
        print(f"âŒ å¤±è´¥è‚¡ç¥¨: {results['failed']}")
    
    logger.info(f"ğŸ“‹ è‚¡ç¥¨åˆ—è¡¨å¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
    
    return results

def print_summary(results, total_elapsed, mode):
    """æ‰“å°å¤„ç†ç»“æœæ‘˜è¦"""
    print(f"\n{'='*70}")
    print(f"ğŸ“Š NASDAQ 100 æ•°æ®è·å–å®Œæˆ - {mode}æ¨¡å¼")
    print(f"{'='*70}")
    
    total_stocks = len(results['success']) + len(results['failed'])
    success_rate = len(results['success']) / total_stocks * 100 if total_stocks > 0 else 0
    
    print(f"âœ… æˆåŠŸ: {len(results['success'])} / {total_stocks}")
    print(f"âŒ å¤±è´¥: {len(results['failed'])} / {total_stocks}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_elapsed/60:.1f} åˆ†é’Ÿ")
    
    if results['details']:
        total_records = sum(detail['records'] for detail in results['details'])
        total_size = sum(detail['file_size_kb'] for detail in results['details'])
        avg_return = sum(detail['total_return'] for detail in results['details']) / len(results['details'])
        
        print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        print(f"   ğŸ”¢ æ€»æ•°æ®æ¡æ•°: {total_records:,}")
        print(f"   ğŸ’¾ æ€»æ–‡ä»¶å¤§å°: {total_size:.1f} KB")
        print(f"   âš¡ å¹³å‡å¤„ç†é€Ÿåº¦: {total_records/total_elapsed:.0f} æ¡/ç§’")
        print(f"   ğŸ“Š å¹³å‡æ”¶ç›Šç‡: {avg_return:+.1f}%")
        
        print(f"\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
        for detail in results['details']:
            print(f"   {detail['symbol']}.csv - {detail['records']:,} æ¡æ•°æ®")
    
    if results['failed']:
        print(f"\nâŒ å¤±è´¥çš„è‚¡ç¥¨: {results['failed']}")
        # éœ€è¦logä¸‹æ¥
        

def main():
    """ä¸»å‡½æ•° - ç®€åŒ–æ¶æ„ï¼Œæ ¹æ®å‚æ•°ç›´æ¥æ‰§è¡Œ"""
    args = parse_arguments()
    
    print("ğŸš€ NASDAQ 100 è‚¡ç¥¨æ•°æ®æ‰¹é‡è·å–å·¥å…·")
    print("è¯·ç¡®ä¿ TWS æˆ– IB Gateway æ­£åœ¨è¿è¡Œ...")
    
    # æ ¹æ®å‚æ•°ç±»å‹ç›´æ¥æ‰§è¡Œç›¸åº”åŠŸèƒ½
    if args.failed_list:
        # å¤±è´¥è‚¡ç¥¨åˆ—è¡¨æ¨¡å¼
        print("ğŸ”„ è¿è¡Œæ¨¡å¼: å¤±è´¥è‚¡ç¥¨é‡è¯•æ¨¡å¼")
        print(f"ğŸ“‹ å¤„ç†è‚¡ç¥¨: {len(args.failed_list)} åª")
        print(f"ğŸ“… å¼€å§‹æ—¥æœŸ: {args.start_date}")
        
        results = fetch_list_stocks(
            stock_list=args.failed_list,
            start_date=args.start_date,
            save_to_csv=True,
            output_dir="data/failed_stocks"
        )
        
        print(f"\nâœ… å¤±è´¥è‚¡ç¥¨å¤„ç†å®Œæˆ!")
        
    else:
        # æ ‡å‡†NASDAQ 100æ¨¡å¼
        nasdaq_df = load_nasdaq100_data()
        if nasdaq_df.empty:
            logger.error("æ— æ³•åŠ è½½ NASDAQ 100 æ•°æ®ï¼Œç¨‹åºé€€å‡º")
            return
        
        if args.test:
            print("ğŸ§ª è¿è¡Œæ¨¡å¼: æµ‹è¯•æ¨¡å¼")
        elif args.full:
            print("ğŸ­ è¿è¡Œæ¨¡å¼: å®Œæ•´æ¨¡å¼")
            print(f"\nâš ï¸  æ³¨æ„: å³å°†è·å–å…¨éƒ¨ {len(nasdaq_df)} åªè‚¡ç¥¨çš„å†å²æ•°æ®")
            print(f"é¢„è®¡è€—æ—¶: {len(nasdaq_df) * 10 / 60:.0f} åˆ†é’Ÿ")
            
            confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/N): ").strip().lower()
            if confirm not in ['y', 'yes']:
                print("ğŸ‘‹ å·²å–æ¶ˆæ“ä½œ")
                return
        
        print(f"ğŸ“‹ æ•°æ®æº: {len(nasdaq_df)} åª NASDAQ 100 è‚¡ç¥¨")
        
        results, total_elapsed = batch_fetch_stocks(
            nasdaq_df,
            test_mode=args.test,
            max_count=args.max_count,
            start_from=args.start_from,
            start_date=args.start_date
        )
        
        # æ‰“å°æ ‡å‡†æ‘˜è¦
        mode = "æµ‹è¯•" if args.test else "å®Œæ•´"
        print_summary(results, total_elapsed, mode)
        
        if results['success']:
            print(f"\nğŸ’¾ æ‰€æœ‰CSVæ–‡ä»¶å·²ä¿å­˜åˆ° data/ ç›®å½•")

if __name__ == "__main__":
    main()
